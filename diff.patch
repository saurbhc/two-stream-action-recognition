diff --git a/dataloader/spatial_dataloader.py b/dataloader/spatial_dataloader.py
index b1d04d0..7d2c767 100644
--- a/dataloader/spatial_dataloader.py
+++ b/dataloader/spatial_dataloader.py
@@ -19,14 +19,26 @@ class spatial_dataset(Dataset):
         return len(self.keys)
 
     def load_ucf_image(self,video_name, index):
+        if index // 1000 != 0:
+            index_temp = '00' + str(index)
+        elif index // 100 != 0:
+            index_temp = '000' + str(index)
+        elif index // 10 != 0:
+            index_temp = '0000' + str(index)
+        else:
+            index_temp = '00000' + str(index)
+
         if video_name.split('_')[0] == 'HandstandPushups':
             n,g = video_name.split('_',1)
             name = 'HandStandPushups_'+g
-            path = self.root_dir + 'HandstandPushups'+'/separated_images/v_'+name+'/v_'+name+'_'
+            # path = self.root_dir + 'HandstandPushups'+'/separated_images/v_'+name+'/v_'+name+'_'
+            path = self.root_dir + 'v_' + video_name + '/' + 'frame'
         else:
-            path = self.root_dir + video_name.split('_')[0]+'/separated_images/v_'+video_name+'/v_'+video_name+'_'
+            # path = self.root_dir + video_name.split('_')[0]+'/separated_images/v_'+video_name+'/v_'+video_name+'_'
+            path = self.root_dir + 'v_' + video_name + '/' + 'frame'
          
-        img = Image.open(path +str(index)+'.jpg')
+        # img = Image.open(path +str(index)+'.jpg')
+        img = Image.open(path + index_temp +'.jpg')
         transformed_img = self.transform(img)
         img.close()
 
@@ -80,7 +92,7 @@ class spatial_dataloader():
 
     def load_frame_count(self):
         #print '==> Loading frame number of each video'
-        with open('dic/frame_count.pickle','rb') as file:
+        with open('/content/two-stream-action-recognition/dataloader/dic/frame_count.pickle','rb') as file:
             dic_frame = pickle.load(file)
         file.close()
 
diff --git a/spatial_cnn.py b/spatial_cnn.py
index e0cb6aa..9f5a2fb 100644
--- a/spatial_cnn.py
+++ b/spatial_cnn.py
@@ -39,8 +39,8 @@ def main():
     data_loader = dataloader.spatial_dataloader(
                         BATCH_SIZE=arg.batch_size,
                         num_workers=8,
-                        path='/home/ubuntu/data/UCF101/spatial_no_sampled/',
-                        ucf_list ='/home/ubuntu/cvlab/pytorch/ucf101_two_stream/github/UCF_list/',
+                        path='/content/jpegs_256/',
+                        ucf_list ='/content/two-stream-action-recognition/UCF_list/',
                         ucf_split ='01', 
                         )
     
@@ -114,7 +114,7 @@ class Spatial_CNN():
             # save model
             if is_best:
                 self.best_prec1 = prec1
-                with open('record/spatial/spatial_video_preds.pickle','wb') as f:
+                with open('/content/two-stream-action-recognition/record/spatial/spatial_video_preds.pickle','wb') as f:
                     pickle.dump(self.dic_video_level_preds,f)
                 f.close()
             
@@ -123,7 +123,7 @@ class Spatial_CNN():
                 'state_dict': self.model.state_dict(),
                 'best_prec1': self.best_prec1,
                 'optimizer' : self.optimizer.state_dict()
-            },is_best,'record/spatial/checkpoint.pth.tar','record/spatial/model_best.pth.tar')
+            },is_best,'/content/two-stream-action-recognition/record/spatial/checkpoint.pth.tar','/content/two-stream-action-recognition/record/spatial/model_best.pth.tar')
 
     def train_1epoch(self):
         print('==> Epoch:[{0}/{1}][training stage]'.format(self.epoch, self.nb_epochs))
@@ -158,9 +158,13 @@ class Spatial_CNN():
 
             # measure accuracy and record loss
             prec1, prec5 = accuracy(output.data, label, topk=(1, 5))
-            losses.update(loss.data[0], data.size(0))
-            top1.update(prec1[0], data.size(0))
-            top5.update(prec5[0], data.size(0))
+            loss_data = loss.data
+            data_size = data.size(0)
+            print(prec1)
+            print(prec5)
+            losses.update(loss_data, data_size)
+            top1.update(prec1, data_size)
+            top5.update(prec5, data_size)
 
             # compute gradient and do SGD step
             self.optimizer.zero_grad()
@@ -179,7 +183,7 @@ class Spatial_CNN():
                 'Prec@5':[round(top5.avg,4)],
                 'lr': self.optimizer.param_groups[0]['lr']
                 }
-        record_info(info, 'record/spatial/rgb_train.csv','train')
+        record_info(info, '/content/two-stream-action-recognition/record/rgb_train.csv','train')
 
     def validate_1epoch(self):
         print('==> Epoch:[{0}/{1}][validation stage]'.format(self.epoch, self.nb_epochs))
@@ -221,7 +225,7 @@ class Spatial_CNN():
                 'Loss':[round(video_loss,5)],
                 'Prec@1':[round(video_top1,3)],
                 'Prec@5':[round(video_top5,3)]}
-        record_info(info, 'record/spatial/rgb_test.csv','test')
+        record_info(info, '/content/two-stream-action-recognition/record/spatial/rgb_test.csv','test')
         return video_top1, video_loss
 
     def frame2_video_level_accuracy(self):
